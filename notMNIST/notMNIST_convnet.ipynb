{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:  (200000, 28, 28) (200000,)\n",
      "Valid Dataset:  (10000, 28, 28) (10000,)\n",
      "Test Dataset:  (18724, 28, 28) (200000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file,'rb') as f:\n",
    "    save =  pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    test_dataset = save['test_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    test_labels = save['test_labels']\n",
    "    valid_labels = save['valid_labels']\n",
    "    del save\n",
    "    print 'Train Dataset: ',train_dataset.shape,train_labels.shape\n",
    "    print 'Valid Dataset: ',valid_dataset.shape,valid_labels.shape\n",
    "    print 'Test Dataset: ',test_dataset.shape,train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 9, 3, ..., 9, 9, 6], dtype=int32),\n",
       " array([[[-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         ..., \n",
       "         [-0.34705883,  0.5       ,  0.36666667, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.08039216,  0.5       ,  0.11176471, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.06078431,  0.44901961, -0.3392157 , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ]],\n",
       " \n",
       "        [[-0.5       , -0.49215686, -0.5       , ..., -0.29215688,\n",
       "          -0.26862746, -0.33529413],\n",
       "         [-0.31568629, -0.00588235,  0.13137256, ...,  0.48431373,\n",
       "           0.42156863,  0.13921569],\n",
       "         [ 0.33137256,  0.5       ,  0.49607843, ..., -0.31568629,\n",
       "          -0.42156863, -0.5       ],\n",
       "         ..., \n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ]],\n",
       " \n",
       "        [[-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         ..., \n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ]],\n",
       " \n",
       "        ..., \n",
       "        [[-0.5       , -0.5       , -0.5       , ...,  0.48823529,\n",
       "           0.40980393,  0.05686275],\n",
       "         [-0.5       , -0.5       , -0.5       , ...,  0.48823529,\n",
       "           0.5       ,  0.40196079],\n",
       "         [-0.5       , -0.5       , -0.5       , ...,  0.5       ,\n",
       "           0.37058824, -0.20980392],\n",
       "         ..., \n",
       "         [-0.5       , -0.15490197,  0.48823529, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.48823529, -0.5       , -0.25294119, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.49215686, -0.5       , ..., -0.5       ,\n",
       "          -0.5       , -0.5       ]],\n",
       " \n",
       "        [[-0.5       , -0.5       , -0.5       , ..., -0.48823529,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.5       ,\n",
       "          -0.48823529, -0.5       ],\n",
       "         [-0.5       , -0.5       , -0.5       , ..., -0.21372549,\n",
       "          -0.5       , -0.48823529],\n",
       "         ..., \n",
       "         [-0.37843138,  0.44509804,  0.49607843, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [-0.1       ,  0.5       ,  0.48823529, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ],\n",
       "         [ 0.17450981,  0.49607843,  0.48823529, ..., -0.5       ,\n",
       "          -0.5       , -0.5       ]],\n",
       " \n",
       "        [[-0.49607843, -0.49215686, -0.5       , ...,  0.5       ,\n",
       "           0.5       ,  0.43725491],\n",
       "         [-0.5       , -0.4254902 ,  0.06470589, ...,  0.5       ,\n",
       "           0.5       ,  0.5       ],\n",
       "         [-0.43333334,  0.26078433,  0.5       , ...,  0.5       ,\n",
       "           0.5       ,  0.49607843],\n",
       "         ..., \n",
       "         [-0.4254902 ,  0.28431374,  0.5       , ...,  0.5       ,\n",
       "           0.5       ,  0.49607843],\n",
       "         [-0.5       , -0.42156863,  0.0882353 , ...,  0.5       ,\n",
       "           0.5       ,  0.5       ],\n",
       "         [-0.49607843, -0.49607843, -0.5       , ...,  0.5       ,\n",
       "           0.5       ,  0.45686275]]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:  (200000, 28, 28, 1) (200000, 10)\n",
      "Valid Dataset:  (10000, 28, 28, 1) (10000, 10)\n",
      "Test Dataset:  (18724, 28, 28, 1) (200000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1\n",
    "\n",
    "def reformat(dataset,labels):\n",
    "    dataset = dataset.reshape((-1,image_size,image_size,num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels)==labels[:,None]).astype(np.float32)\n",
    "    return dataset,labels\n",
    "train_dataset,train_labels = reformat(train_dataset,train_labels)\n",
    "valid_dataset,valid_labels = reformat(valid_dataset,valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset,test_labels)\n",
    "\n",
    "print 'Train Dataset: ',train_dataset.shape,train_labels.shape\n",
    "print 'Valid Dataset: ',valid_dataset.shape,valid_labels.shape\n",
    "print 'Test Dataset: ',test_dataset.shape,train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions,labels):\n",
    "    return (100.0*np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)))/predictions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size,image_size,image_size,num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32,shape=(batch_size,num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    layer_w1 = tf.Variable(tf.truncated_normal([patch_size,patch_size,num_channels,depth],stddev=0.1))\n",
    "    layer_b1 = tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    layer_w2 = tf.Variable(tf.truncated_normal([patch_size,patch_size,depth,depth],stddev=0.1))\n",
    "    layer_b2 = tf.Variable(tf.constant(1.0,shape=[depth]))\n",
    "    \n",
    "    layer_w3 = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer_b3 = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    layer_w4 = tf.Variable(tf.truncated_normal([num_hidden,num_labels],stddev=0.1))\n",
    "    layer_b4 = tf.Variable(tf.constant(1.0,shape=[num_labels]))\n",
    "    \n",
    "    def model(data):\n",
    "        conv = tf.nn.conv2d(data,layer_w1,[1,2,2,1],padding='SAME')\n",
    "        hidden = tf.nn.relu(conv+layer_b1)\n",
    "        conv = tf.nn.conv2d(hidden,layer_w2,[1,2,2,1],padding='SAME')\n",
    "        hidden = tf.nn.relu(conv+layer_b2)\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        hidden = tf.matmul(reshape,layer_w3)+layer_b3\n",
    "        hidden = tf.nn.relu(hidden)\n",
    "        return tf.matmul(hidden,layer_w4)+layer_b4\n",
    "    \n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits=logits))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(test_dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "0:\n",
      "Batch Loss: 2.78846\n",
      "Batch Accuracy: 18.75%\n",
      "Validation Accuracy: 10.18%\n",
      "\n",
      "50:\n",
      "Batch Loss: 1.13397\n",
      "Batch Accuracy: 56.25%\n",
      "Validation Accuracy: 64.52%\n",
      "\n",
      "100:\n",
      "Batch Loss: 0.861956\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 74.69%\n",
      "\n",
      "150:\n",
      "Batch Loss: 1.18869\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 76.17%\n",
      "\n",
      "200:\n",
      "Batch Loss: 1.00891\n",
      "Batch Accuracy: 68.75%\n",
      "Validation Accuracy: 76.48%\n",
      "\n",
      "250:\n",
      "Batch Loss: 0.38222\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 79.55%\n",
      "\n",
      "300:\n",
      "Batch Loss: 0.373316\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 79.92%\n",
      "\n",
      "350:\n",
      "Batch Loss: 0.511557\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 80.72%\n",
      "\n",
      "400:\n",
      "Batch Loss: 0.133208\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 80.32%\n",
      "\n",
      "450:\n",
      "Batch Loss: 0.672095\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 81.49%\n",
      "\n",
      "500:\n",
      "Batch Loss: 0.749888\n",
      "Batch Accuracy: 68.75%\n",
      "Validation Accuracy: 80.96%\n",
      "\n",
      "550:\n",
      "Batch Loss: 0.249885\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 81.49%\n",
      "\n",
      "600:\n",
      "Batch Loss: 0.597276\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 80.64%\n",
      "\n",
      "650:\n",
      "Batch Loss: 0.696602\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 80.39%\n",
      "\n",
      "700:\n",
      "Batch Loss: 1.1931\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 81.86%\n",
      "\n",
      "750:\n",
      "Batch Loss: 0.570868\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 81.78%\n",
      "\n",
      "800:\n",
      "Batch Loss: 0.561367\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 82.9%\n",
      "\n",
      "850:\n",
      "Batch Loss: 0.413591\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 82.38%\n",
      "\n",
      "900:\n",
      "Batch Loss: 0.205946\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 82.06%\n",
      "\n",
      "950:\n",
      "Batch Loss: 0.615104\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 82.94%\n",
      "\n",
      "1000:\n",
      "Batch Loss: 0.469949\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 82.81%\n",
      "\n",
      "Test Accuracy: 89.6603289895%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print 'Initialized\\n'\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "        batch_data = train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size),:]\n",
    "        feed_dict = {tf_train_dataset:batch_data,tf_train_labels:batch_labels}\n",
    "        \n",
    "        _,l,predictions = session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n",
    "        \n",
    "        if step%50==0:\n",
    "            print str(step)+':'\n",
    "            print 'Batch Loss: '+str(l)\n",
    "            print 'Batch Accuracy: '+str(accuracy(predictions,batch_labels))+'%'\n",
    "            print 'Validation Accuracy: '+str(accuracy(valid_prediction.eval(),valid_labels))+'%\\n'\n",
    "    print 'Test Accuracy: '+str(accuracy(test_prediction.eval(),test_labels))+'%'\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size,image_size,image_size,num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32,shape=(batch_size,num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    layer_w1 = tf.Variable(tf.truncated_normal([patch_size,patch_size,num_channels,depth],stddev=0.1))\n",
    "    layer_b1 = tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    layer_w2 = tf.Variable(tf.truncated_normal([patch_size,patch_size,depth,depth],stddev=0.1))\n",
    "    layer_b2 = tf.Variable(tf.constant(1.0,shape=[depth]))\n",
    "    \n",
    "    layer_w3 = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer_b3 = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    layer_w4 = tf.Variable(tf.truncated_normal([num_hidden,num_labels],stddev=0.1))\n",
    "    layer_b4 = tf.Variable(tf.constant(1.0,shape=[num_labels]))\n",
    "    \n",
    "    def model(data):\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(data,layer_w1,[1,1,1,1],padding='SAME'))\n",
    "        pool = tf.nn.max_pool(conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(pool,layer_w2,[1,1,1,1],padding='SAME'))\n",
    "        pool = tf.nn.max_pool(conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        pool = tf.matmul(reshape,layer_w3)+layer_b3\n",
    "        pool = tf.nn.relu(pool)\n",
    "        return tf.matmul(pool,layer_w4)+layer_b4\n",
    "    \n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits=logits))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "0:\n",
      "Batch Loss: 2.91537\n",
      "Batch Accuracy: 6.25%\n",
      "Validation Accuracy: 12.9%\n",
      "\n",
      "50:\n",
      "Batch Loss: 1.2105\n",
      "Batch Accuracy: 56.25%\n",
      "Validation Accuracy: 64.65%\n",
      "\n",
      "100:\n",
      "Batch Loss: 1.13393\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 75.96%\n",
      "\n",
      "150:\n",
      "Batch Loss: 1.1764\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 77.49%\n",
      "\n",
      "200:\n",
      "Batch Loss: 0.887419\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 76.19%\n",
      "\n",
      "250:\n",
      "Batch Loss: 0.314069\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 80.73%\n",
      "\n",
      "300:\n",
      "Batch Loss: 0.318696\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 80.77%\n",
      "\n",
      "350:\n",
      "Batch Loss: 0.324049\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 82.32%\n",
      "\n",
      "400:\n",
      "Batch Loss: 0.0780629\n",
      "Batch Accuracy: 100.0%\n",
      "Validation Accuracy: 82.31%\n",
      "\n",
      "450:\n",
      "Batch Loss: 0.649593\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 83.06%\n",
      "\n",
      "500:\n",
      "Batch Loss: 0.497171\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 82.76%\n",
      "\n",
      "550:\n",
      "Batch Loss: 0.259662\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 82.43%\n",
      "\n",
      "600:\n",
      "Batch Loss: 0.497851\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 83.48%\n",
      "\n",
      "650:\n",
      "Batch Loss: 0.400871\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 83.41%\n",
      "\n",
      "700:\n",
      "Batch Loss: 0.9529\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 83.47%\n",
      "\n",
      "750:\n",
      "Batch Loss: 0.430749\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 83.46%\n",
      "\n",
      "800:\n",
      "Batch Loss: 0.565234\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 84.5%\n",
      "\n",
      "850:\n",
      "Batch Loss: 0.371977\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 83.88%\n",
      "\n",
      "900:\n",
      "Batch Loss: 0.136504\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 84.63%\n",
      "\n",
      "950:\n",
      "Batch Loss: 0.820612\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 85.02%\n",
      "\n",
      "1000:\n",
      "Batch Loss: 0.431333\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 84.37%\n",
      "\n",
      "Test Accuracy: 90.7017731254%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print 'Initialized\\n'\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "        batch_data = train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size),:]\n",
    "        feed_dict = {tf_train_dataset:batch_data,tf_train_labels:batch_labels}\n",
    "        \n",
    "        _,l,predictions = session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n",
    "        \n",
    "        if step%50==0:\n",
    "            print str(step)+':'\n",
    "            print 'Batch Loss: '+str(l)\n",
    "            print 'Batch Accuracy: '+str(accuracy(predictions,batch_labels))+'%'\n",
    "            print 'Validation Accuracy: '+str(accuracy(valid_prediction.eval(),valid_labels))+'%\\n'\n",
    "    print 'Test Accuracy: '+str(accuracy(test_prediction.eval(),test_labels))+'%'\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "num_steps = 30001\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size,image_size,image_size,num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32,shape=(batch_size,num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    layer_w1 = tf.Variable(tf.truncated_normal([patch_size,patch_size,num_channels,depth],stddev=0.1))\n",
    "    layer_b1 = tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    layer_w2 = tf.Variable(tf.truncated_normal([patch_size,patch_size,depth,depth],stddev=0.1))\n",
    "    layer_b2 = tf.Variable(tf.constant(1.0,shape=[depth]))\n",
    "    \n",
    "    layer_w3 = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer_b3 = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    layer_w4 = tf.Variable(tf.truncated_normal([num_hidden,num_labels],stddev=0.1))\n",
    "    layer_b4 = tf.Variable(tf.constant(1.0,shape=[num_labels]))\n",
    "    \n",
    "    def model(data,keep_prob):\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(data,layer_w1,[1,1,1,1],padding='SAME'))\n",
    "        pool = tf.nn.max_pool(conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(pool,layer_w2,[1,1,1,1],padding='SAME'))\n",
    "        pool = tf.nn.max_pool(conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        pool = tf.matmul(reshape,layer_w3)+layer_b3\n",
    "        pool = tf.nn.relu(pool)\n",
    "        pool = tf.nn.dropout(pool,keep_prob)\n",
    "        \n",
    "        return tf.nn.softmax(tf.matmul(pool,layer_w4)+layer_b4)\n",
    "    \n",
    "    \n",
    "    def model2(data):\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(data,layer_w1,[1,1,1,1],padding='SAME'))\n",
    "        pool = tf.nn.max_pool(conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        conv = tf.nn.relu(tf.nn.conv2d(pool,layer_w2,[1,1,1,1],padding='SAME'))\n",
    "        pool = tf.nn.max_pool(conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        pool = tf.matmul(reshape,layer_w3)+layer_b3\n",
    "        pool = tf.nn.relu(pool)\n",
    "        \n",
    "        return tf.nn.softmax(tf.matmul(pool,layer_w4)+layer_b4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = model(tf_train_dataset, 0.5)\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(tf_train_labels* tf.log(model), reduction_indices=[1]))\n",
    "    \n",
    "    loss = cross_entropy + 0.001 * (tf.nn.l2_loss(layer_w3) + tf.nn.l2_loss(layer_b3) + tf.nn.l2_loss(layer_w4) + tf.nn.l2_loss(layer_b4))\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(1e-1, global_step, num_steps, 0.7, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    train_prediction = model\n",
    "    valid_prediction = model2(tf_valid_dataset)\n",
    "    test_prediction = model2(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "0:\n",
      "Batch Loss: 3.21239\n",
      "Batch Accuracy: 0.0%\n",
      "Validation Accuracy: 13.75%\n",
      "\n",
      "300:\n",
      "Batch Loss: 0.81148\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 79.84%\n",
      "\n",
      "600:\n",
      "Batch Loss: 1.04903\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 82.68%\n",
      "\n",
      "900:\n",
      "Batch Loss: 0.659055\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 84.19%\n",
      "\n",
      "1200:\n",
      "Batch Loss: 1.10591\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 84.12%\n",
      "\n",
      "1500:\n",
      "Batch Loss: 0.662814\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 85.59%\n",
      "\n",
      "1800:\n",
      "Batch Loss: 0.786785\n",
      "Batch Accuracy: 68.75%\n",
      "Validation Accuracy: 85.98%\n",
      "\n",
      "2100:\n",
      "Batch Loss: 0.785577\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 85.64%\n",
      "\n",
      "2400:\n",
      "Batch Loss: 0.573866\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 84.9%\n",
      "\n",
      "2700:\n",
      "Batch Loss: 0.907325\n",
      "Batch Accuracy: 68.75%\n",
      "Validation Accuracy: 86.2%\n",
      "\n",
      "3000:\n",
      "Batch Loss: 0.694408\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 84.68%\n",
      "\n",
      "3300:\n",
      "Batch Loss: 0.618389\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 86.25%\n",
      "\n",
      "3600:\n",
      "Batch Loss: 0.989295\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 86.35%\n",
      "\n",
      "3900:\n",
      "Batch Loss: 0.453406\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 86.77%\n",
      "\n",
      "4200:\n",
      "Batch Loss: 0.666141\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 87.44%\n",
      "\n",
      "4500:\n",
      "Batch Loss: 0.213135\n",
      "Batch Accuracy: 100.0%\n",
      "Validation Accuracy: 86.69%\n",
      "\n",
      "4800:\n",
      "Batch Loss: 0.980267\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 87.13%\n",
      "\n",
      "5100:\n",
      "Batch Loss: 1.104\n",
      "Batch Accuracy: 68.75%\n",
      "Validation Accuracy: 86.86%\n",
      "\n",
      "5400:\n",
      "Batch Loss: 0.568808\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 87.16%\n",
      "\n",
      "5700:\n",
      "Batch Loss: 1.0182\n",
      "Batch Accuracy: 62.5%\n",
      "Validation Accuracy: 87.65%\n",
      "\n",
      "6000:\n",
      "Batch Loss: 0.391971\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 87.4%\n",
      "\n",
      "6300:\n",
      "Batch Loss: 0.592194\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.89%\n",
      "\n",
      "6600:\n",
      "Batch Loss: 0.861079\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 87.94%\n",
      "\n",
      "6900:\n",
      "Batch Loss: 0.275895\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 87.71%\n",
      "\n",
      "7200:\n",
      "Batch Loss: 0.555286\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.43%\n",
      "\n",
      "7500:\n",
      "Batch Loss: 0.894924\n",
      "Batch Accuracy: 62.5%\n",
      "Validation Accuracy: 87.9%\n",
      "\n",
      "7800:\n",
      "Batch Loss: 0.69856\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.55%\n",
      "\n",
      "8100:\n",
      "Batch Loss: 0.258602\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.21%\n",
      "\n",
      "8400:\n",
      "Batch Loss: 0.282402\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.58%\n",
      "\n",
      "8700:\n",
      "Batch Loss: 0.293656\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.26%\n",
      "\n",
      "9000:\n",
      "Batch Loss: 0.298551\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 87.91%\n",
      "\n",
      "9300:\n",
      "Batch Loss: 0.640458\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.31%\n",
      "\n",
      "9600:\n",
      "Batch Loss: 0.724391\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 87.93%\n",
      "\n",
      "9900:\n",
      "Batch Loss: 0.660617\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 87.96%\n",
      "\n",
      "10200:\n",
      "Batch Loss: 1.24589\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 87.0%\n",
      "\n",
      "10500:\n",
      "Batch Loss: 0.379211\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.42%\n",
      "\n",
      "10800:\n",
      "Batch Loss: 0.716151\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 88.19%\n",
      "\n",
      "11100:\n",
      "Batch Loss: 0.617541\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.11%\n",
      "\n",
      "11400:\n",
      "Batch Loss: 0.402697\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.41%\n",
      "\n",
      "11700:\n",
      "Batch Loss: 0.3197\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.45%\n",
      "\n",
      "12000:\n",
      "Batch Loss: 0.673084\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.07%\n",
      "\n",
      "12300:\n",
      "Batch Loss: 0.717193\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 88.56%\n",
      "\n",
      "12600:\n",
      "Batch Loss: 0.423432\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.56%\n",
      "\n",
      "12900:\n",
      "Batch Loss: 0.605502\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.43%\n",
      "\n",
      "13200:\n",
      "Batch Loss: 0.175124\n",
      "Batch Accuracy: 100.0%\n",
      "Validation Accuracy: 88.35%\n",
      "\n",
      "13500:\n",
      "Batch Loss: 0.458838\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.37%\n",
      "\n",
      "13800:\n",
      "Batch Loss: 0.504217\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.74%\n",
      "\n",
      "14100:\n",
      "Batch Loss: 0.725295\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.14%\n",
      "\n",
      "14400:\n",
      "Batch Loss: 0.549927\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.55%\n",
      "\n",
      "14700:\n",
      "Batch Loss: 0.601406\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 87.93%\n",
      "\n",
      "15000:\n",
      "Batch Loss: 0.493286\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.99%\n",
      "\n",
      "15300:\n",
      "Batch Loss: 0.536363\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.99%\n",
      "\n",
      "15600:\n",
      "Batch Loss: 0.226615\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.17%\n",
      "\n",
      "15900:\n",
      "Batch Loss: 0.536875\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.3%\n",
      "\n",
      "16200:\n",
      "Batch Loss: 0.698648\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.25%\n",
      "\n",
      "16500:\n",
      "Batch Loss: 0.349633\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.91%\n",
      "\n",
      "16800:\n",
      "Batch Loss: 0.465709\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 88.42%\n",
      "\n",
      "17100:\n",
      "Batch Loss: 0.499846\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.48%\n",
      "\n",
      "17400:\n",
      "Batch Loss: 0.284929\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.53%\n",
      "\n",
      "17700:\n",
      "Batch Loss: 0.251433\n",
      "Batch Accuracy: 100.0%\n",
      "Validation Accuracy: 89.12%\n",
      "\n",
      "18000:\n",
      "Batch Loss: 0.438652\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.98%\n",
      "\n",
      "18300:\n",
      "Batch Loss: 0.591036\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.53%\n",
      "\n",
      "18600:\n",
      "Batch Loss: 0.473956\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.71%\n",
      "\n",
      "18900:\n",
      "Batch Loss: 0.380233\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 89.21%\n",
      "\n",
      "19200:\n",
      "Batch Loss: 0.551891\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.97%\n",
      "\n",
      "19500:\n",
      "Batch Loss: 0.717325\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.89%\n",
      "\n",
      "19800:\n",
      "Batch Loss: 0.699533\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 89.08%\n",
      "\n",
      "20100:\n",
      "Batch Loss: 0.940771\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 88.43%\n",
      "\n",
      "20400:\n",
      "Batch Loss: 0.812755\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 88.49%\n",
      "\n",
      "20700:\n",
      "Batch Loss: 0.943123\n",
      "Batch Accuracy: 62.5%\n",
      "Validation Accuracy: 88.78%\n",
      "\n",
      "21000:\n",
      "Batch Loss: 0.731373\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.64%\n",
      "\n",
      "21300:\n",
      "Batch Loss: 0.306295\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.97%\n",
      "\n",
      "21600:\n",
      "Batch Loss: 0.306881\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.68%\n",
      "\n",
      "21900:\n",
      "Batch Loss: 0.269353\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.46%\n",
      "\n",
      "22200:\n",
      "Batch Loss: 0.696219\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.3%\n",
      "\n",
      "22500:\n",
      "Batch Loss: 0.448854\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.77%\n",
      "\n",
      "22800:\n",
      "Batch Loss: 0.712114\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.44%\n",
      "\n",
      "23100:\n",
      "Batch Loss: 0.266707\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.71%\n",
      "\n",
      "23400:\n",
      "Batch Loss: 0.443641\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 87.61%\n",
      "\n",
      "23700:\n",
      "Batch Loss: 1.07647\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 89.04%\n",
      "\n",
      "24000:\n",
      "Batch Loss: 0.316345\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.45%\n",
      "\n",
      "24300:\n",
      "Batch Loss: 0.541058\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.59%\n",
      "\n",
      "24600:\n",
      "Batch Loss: 0.401097\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.44%\n",
      "\n",
      "24900:\n",
      "Batch Loss: 0.25186\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.66%\n",
      "\n",
      "25200:\n",
      "Batch Loss: 0.365793\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.9%\n",
      "\n",
      "25500:\n",
      "Batch Loss: 0.479584\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.94%\n",
      "\n",
      "25800:\n",
      "Batch Loss: 0.312325\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.51%\n",
      "\n",
      "26100:\n",
      "Batch Loss: 0.513993\n",
      "Batch Accuracy: 87.5%\n",
      "Validation Accuracy: 88.89%\n",
      "\n",
      "26400:\n",
      "Batch Loss: 0.978719\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 89.15%\n",
      "\n",
      "26700:\n",
      "Batch Loss: 0.730089\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 87.45%\n",
      "\n",
      "27000:\n",
      "Batch Loss: 0.743768\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 89.1%\n",
      "\n",
      "27300:\n",
      "Batch Loss: 1.07178\n",
      "Batch Accuracy: 68.75%\n",
      "Validation Accuracy: 88.68%\n",
      "\n",
      "27600:\n",
      "Batch Loss: 0.154718\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.94%\n",
      "\n",
      "27900:\n",
      "Batch Loss: 0.279489\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 89.04%\n",
      "\n",
      "28200:\n",
      "Batch Loss: 0.466098\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 89.15%\n",
      "\n",
      "28500:\n",
      "Batch Loss: 0.345749\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.95%\n",
      "\n",
      "28800:\n",
      "Batch Loss: 0.531205\n",
      "Batch Accuracy: 75.0%\n",
      "Validation Accuracy: 88.15%\n",
      "\n",
      "29100:\n",
      "Batch Loss: 0.68059\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 89.27%\n",
      "\n",
      "29400:\n",
      "Batch Loss: 0.435426\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 88.66%\n",
      "\n",
      "29700:\n",
      "Batch Loss: 0.463341\n",
      "Batch Accuracy: 81.25%\n",
      "Validation Accuracy: 88.73%\n",
      "\n",
      "30000:\n",
      "Batch Loss: 0.417978\n",
      "Batch Accuracy: 93.75%\n",
      "Validation Accuracy: 89.15%\n",
      "\n",
      "Test Accuracy: 95.0544755394%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print 'Initialized\\n'\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step*batch_size)%(train_labels.shape[0]-batch_size)\n",
    "        batch_data = train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size),:]\n",
    "        feed_dict = {tf_train_dataset:batch_data,tf_train_labels:batch_labels}\n",
    "        \n",
    "        _,l,predictions = session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n",
    "        \n",
    "        if step%300==0:\n",
    "            print str(step)+':'\n",
    "            print 'Batch Loss: '+str(l)\n",
    "            print 'Batch Accuracy: '+str(accuracy(predictions,batch_labels))+'%'\n",
    "            print 'Validation Accuracy: '+str(accuracy(valid_prediction.eval(),valid_labels))+'%\\n'\n",
    "    print 'Test Accuracy: '+str(accuracy(test_prediction.eval(),test_labels))+'%'\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
